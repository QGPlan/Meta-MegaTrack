{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    " \n",
    "# # HACK\n",
    "# # We're adding our parent directory to sys.path so that we can get DetNet. Ughghghghgh why is Python so terrible at this\n",
    "# # See also https://stackoverflow.com/questions/52119454/how-to-obtain-jupyter-notebooks-path - I think this is the ONLY way of doing this!!! Burn Python with fire!!!\n",
    "# sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "import torch\n",
    "import DetNet\n",
    "\n",
    "\n",
    "net = DetNet.DetNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = torch.randn(1,1,160, 120)\n",
    "inp = torch.randn(1,1,240,320)\n",
    "\n",
    "checkpoint_file = os.path.join(\n",
    "    \"checkpoints\", 'checkpoint.pth'\n",
    ")\n",
    "\n",
    "if os.path.exists(checkpoint_file):\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=torch.device('cpu'))\n",
    "    net.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    print(\"loaded state dict\")\n",
    "\n",
    "net.eval()\n",
    "e = net.forward(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "torch.onnx.export(net,         # model being run\n",
    "                  inp,       # model input (or a tuple for multiple inputs)\n",
    "                  \"blerg.onnx\",       # where to save the model\n",
    "                  export_params=True,  # store the trained parameter weights inside the model file\n",
    "                  opset_version=13,    # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names=['inputImg'],   # the model's input names\n",
    "                  output_names = [\"hand_exists\", \"cx\", \"cy\", \"size\"]\n",
    "                  # output_names=['heatmap_xy', 'heatmap_depth', 'scalar_extras'],  # the model's output names\n",
    "                  verbose=False,\n",
    "                  # dynamic_axes={'inputImg': {0: 'batch_size'}, 'lastKeypoints': },    # variable length axes\n",
    "                  #                 'x_axis_hmap': {0: 'batch_size'},\n",
    "                  #                 'y_axis_hmap': {0: 'batch_size'}}\n",
    "                  )\n",
    "print(\" \")\n",
    "print('Model has been converted to ONNX')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
